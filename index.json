[{"authors":null,"categories":null,"content":"Hi! I am a PhD Student at INSA Lyon working jointly with the LIRIS and LAGEPP research labs. I am directed by Julie Digne, Christian Wolf and Madiha Nadri.\nI am interested in physics-involved machine learning problems, such as future forecasting of fluid flow, dynamical system modelling/control, and robotics. I like to work on hybrid methods joining physical prior knowledge with cutting-edge machine learning techniques to enjoy the benefits of both worlds !\nI received two master’s degrees, one in electrical engineering and signal processing, and another in artificial intelligence. I also have a teacher degree (professeur agrégatif) in engineering and computer science.\n","date":1677628800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677628800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi! I am a PhD Student at INSA Lyon working jointly with the LIRIS and LAGEPP research labs. I am directed by Julie Digne, Christian Wolf and Madiha Nadri.\nI am interested in physics-involved machine learning problems, such as future forecasting of fluid flow, dynamical system modelling/control, and robotics.","tags":null,"title":"Steeven Janny","type":"authors"},{"authors":["Quentin Possamaï","Steeven Janny","Guillaume Bono","Madiha Nadri","Laurent Bako","Christian Wolf"],"categories":null,"content":"The emergence of data-driven approaches for control and planning in robotics have highlighted the need for developing experimental robotic platforms for data collection. However, their implementation is often complex and expensive, in particular for flying and terrestrial robots where the precise estimation of the position requires motion capture devices (MoCap) or Lidar. In order to simplify the use of a robotic platform dedicated to research on a wide range of indoor and outdoor environments, we present a data validation tool for ego-pose estimation that does not require any equipment other than the on-board camera. The method and tool allow a rapid, visual and quantitative evaluation of the quality of ego-pose sensors and are sensitive to different sources of flaws in the acquisition chain, ranging from desynchronization of the sensor flows to misevaluation of the geometric parameters of the robotic platform. Using computer vision, the information from the sensors is used to calculate the motion of a semantic scene point through its projection to the 2D image space of the on-board camera. The deviations of these keypoints from references created with a semi-automatic tool allow rapid and simple quality assessment of the data collected on the platform. To demonstrate the performance of our method, we evaluate it on two challenging standard UAV datasets as well as one dataset taken from a terrestrial robot.\n","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"cd35cc7055cd7cbc87eeb6037b66d79d","permalink":"https://steevenjanny.github.io/post/mocapless/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/post/mocapless/","section":"post","summary":"ArXiv Preprint","tags":["control"],"title":"MoCap-less Quantitative Evaluation of Ego-Pose Estimation Without Ground Truth Measurements","type":"post"},{"authors":["Azadeh Sadat Mozafari","Hugo Siqueira Gomes","Wilson Leao","Steeven Janny","Christian Gagné"],"categories":null,"content":"Recently, Deep Neural Networks (DNNs) have been achieving impressive results on wide range of tasks. However, they suffer from being well-calibrated. In decision-making applications, such as autonomous driving or medical diagnosing, the confidence of deep networks plays an important role to bring the trust and reliability to the system. To calibrate the deep networks’ confidence, many probabilistic and measure-based approaches are proposed. Temperature Scaling (TS) is a state-of-the-art among measure-based calibration methods which has low time and memory complexity as well as effectiveness. In this paper, we study TS and show it does not work properly when the validation set that TS uses for calibration has small size or contains noisy-labeled samples. TS also cannot calibrate highly accurate networks as well as non-highly accurate ones. Accordingly, we propose Attended Temperature Scaling (ATS) which preserves the advantages of TS while improves calibration in aforementioned challenging situations. We provide theoretical justifications for ATS and assess its effectiveness on wide range of deep models and datasets. We also compare the calibration results of TS and ATS on skin lesion detection application as a practical problem where well-calibrated system can play important role in making a decision.\n","date":1540598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540598400,"objectID":"a9f11f9b40dd05cd948bbb7f84b269db","permalink":"https://steevenjanny.github.io/post/attendedtemperature/","publishdate":"2018-10-27T00:00:00Z","relpermalink":"/post/attendedtemperature/","section":"post","summary":"ArXiv Preprint","tags":[],"title":"Attended temperature scaling: a practical approach for calibrating deep neural networks","type":"post"},{"authors":["Steeven Janny","Wenqi Shu-Quartier-Dit-Maire","Théodore Cherrière","Jeanne Redaud"],"categories":null,"content":"[English]\nThis book aims to present, with clarity, all the knowledge necessary for the first and second years of preparatory classes:\nThe basis of procedural programming in Python; Courses retracing the program of preparatory classes; Corrected exercises and training for the written and oral tests of the competitions; Additional resources. [French]\nCet ouvrage a pour but de présenter, avec clarté, toutes les connaissances nécessaires aux premières et deuxièmes années de classes préparatoires :\nLa base de la programmation procédurale en Python ; Des cours retraçant le programme des classes préparatoires ; Des exercices corrigés et des entrainements aux épreuves écrites et orales des concours ; Des ressources complémentaires. ","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"86ecf9c87ad02590e44a276a6aa36d94","permalink":"https://steevenjanny.github.io/post/informatiqueellipses/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/post/informatiqueellipses/","section":"post","summary":"Editions Ellipses","tags":["books"],"title":"ITC, informatique tronc commun PSI, MP, PC","type":"post"},{"authors":["Théodore Cherrière","Steeven Janny","Jeanne Redaud","Alexandre Daby-Seesaram"],"categories":null,"content":"[English]\nThis book includes:\nA selection of the most representative exercises from the oral examinations for the X, ENS, Centrale-Supélec, Mines-Ponts and CCINP competitions. Answers enriched with comments including: method points, course reminders, remarks on questions, writing advice, remarks from jury reports, etc. [French]\nCet ouvrage regroupe :\nUne sélection d’exercices les plus représentatifs des oraux des concours X, ENS, Centrale-Supélec, Mines-Ponts et CCINP. Des corrigés enrichis de commentaires comportant : des points méthodes, des rappels de cours, des remarques sur les questions, des conseils de rédaction, des remarques issues des rapports de jurys, etc. ","date":1608163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608163200,"objectID":"997597bbe9d826ce03c9be82732ceefb","permalink":"https://steevenjanny.github.io/post/physiqueellipses/","publishdate":"2020-12-17T00:00:00Z","relpermalink":"/post/physiqueellipses/","section":"post","summary":"Editions Ellipses","tags":["books"],"title":"Physique-chimie PSI-PSI* Concours X, ENS, CentraleSupélec, Mines-Ponts, CCINP","type":"post"},{"authors":["Mathieu Marchand","Vincent Andrieu","Sylvain Bertrand","Steeven Janny","Hélène Piet-Lahanier"],"categories":null,"content":"The problem of learning a communication policy is investigated in this paper for the design of an event-triggered observer for discrete-time LTI systems. Firstly, the event-triggered observer problem is formulated as an optimisation problem. The existence of a solution to this problem (communication policy) is investigated and it is verified if this solution still preserves the stability of the estimation error dynamics. Secondly, an algorithm is provided to approximate this optimal solution using neural networks and deep learning. Simulation examples are provided to illustrate the effectiveness of the learned communication policies.\n","date":1677628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677628800,"objectID":"69197b554dba289400886dafe215a2e9","permalink":"https://steevenjanny.github.io/post/eventtrigger/","publishdate":"2023-03-01T00:00:00Z","relpermalink":"/post/eventtrigger/","section":"post","summary":"International Federation of Automatic Control (IFAC) 2023","tags":["control"],"title":"Deep Learning of a Communication Policy for an Event-Triggered Observer for Linear Systems","type":"post"},{"authors":["Quentin Possamaï","Steeven Janny","Madiha Nadri","Laurent Bako","Christian Wolf"],"categories":null,"content":"Controlling UAV flights precisely requires a realistic dynamic model and accurate state estimates from onboard sensors like UAV, GPS and visual observations. Obtaining a precise dynamic model is extremely difficult, as important aerodynamic effects are hard to model, in particular ground effect and other turbulences. While machine learning has been used in the past to estimate UAV created turbulence, this was restricted to flat grounds or diffuse in-flight air turbulences, both without taking into account obstacles. In this work we address the complex problem of estimating in-flight turbulences caused by obstacles, in particular the complex structures in cluttered environments. We learn a mapping from control input and images captured by onboard cameras to turbulence. In a large-scale setting, we train a model over a large number of different simulated photo-realistic environments loaded into the Habitat simulator augmented with a dynamic UAV model and an analytic ground effect model. We transfer the model from simulation to a real environment and evaluate on real UAV flights from the EuRoC-MAV dataset, showing that the model is capable of good sim2real generalization performance. The dataset will be made publicly available upon acceptance.\n","date":1648425600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648425600,"objectID":"23dd3835fa283f606651bcd0ce83c345","permalink":"https://steevenjanny.github.io/post/turbulences/","publishdate":"2022-03-28T00:00:00Z","relpermalink":"/post/turbulences/","section":"post","summary":"ArXiv Preprint","tags":["control"],"title":"Learning to estimate UAV created turbulence from scene structure observed by onboard cameras","type":"post"},{"authors":["Samuele Zoboli","Steeven Janny","Mattia Giaccagli"],"categories":null,"content":"In this paper, we deal with output tracking control problems for input-affine nonlinear systems. We propose a deep learning-based solution whose foundations lay in control theory. We design a two-step controller: a contraction-based feedback stabilizer and feedforward action. The first component guarantees convergence to the steady-state trajectory on which the tracking error is zero. The second one is inherited from output regulation theory and provides forward invariantness of such a trajectory along the solutions of the system. To alleviate the need for heavy analytical computations or online optimization, we rely on deep neural networks and link their approximation error to the tracking one. Mimicking the analytical control structure, we split the learning task into two separate modules. For the stabilizer module, we propose a switching objective function balancing feasibility of the solution and performance improvement. We test our solution in a challenging environment to validate the proposed design.\n","date":1677628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677628800,"objectID":"5cb5b260e0fb48109c94fc3cba4baf4e","permalink":"https://steevenjanny.github.io/post/outputregulation/","publishdate":"2023-03-01T00:00:00Z","relpermalink":"/post/outputregulation/","section":"post","summary":"International Federation of Automatic Control (IFAC) 2023","tags":["control"],"title":"Deep Learning-based Output Tracking via Regulation and Contraction Theory ","type":"post"},{"authors":["Steeven Janny","Quentin Possamaï","Laurent Bako","Madiha Nadri","Christian Wolf"],"categories":null,"content":"The identification of a nonlinear dynamic model is an open topic in control theory, especially from sparse input-output measurements. A fundamental challenge of this problem is that very few to zero prior knowledge is available on both the state and the nonlinear system model. To cope with this challenge, we investigate the effectiveness of deep learning in the modeling of dynamic systems with nonlinear behavior by advocating an approach which relies on three main ingredients: (i) we show that under some structural conditions on the to-be-identified model, the state can be expressed in function of a sequence of the past inputs and outputs; (ii) this relation which we call the state map can be modelled by resorting to the well-documented approximation power of deep neural networks; (iii) taking then advantage of existing learning schemes, a state-space model can be finally identified. After the formulation and analysis of the approach, we show its ability to identify three different nonlinear systems. The performances are evaluated in terms of open-loop prediction on test data generated in simulation as well as a real world data-set of unmanned aerial vehicle flight measurements.\n","date":1650326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650326400,"objectID":"c726f3e734b103843e900492418015d4","permalink":"https://steevenjanny.github.io/post/reducedstatespace/","publishdate":"2021-03-23T00:00:00Z","relpermalink":"/post/reducedstatespace/","section":"post","summary":"Conference on Decision and Control (CDC 2022)","tags":["control","highlights"],"title":"Learning Reduced Nonlinear State-Space Models: an Output-Error Based Canonical Approach","type":"post"},{"authors":["Steeven Janny","Vincent Andrieu","Madiha Nadri","Christian Wolf"],"categories":null,"content":"We address the problem of output prediction, ie. designing a model for autonomous nonlinear systems capable of forecasting their future observations. We first define a general framework bringing together the necessary properties for the development of such an output predictor. In particular, we look at this problem from two different viewpoints, control theory and data-driven techniques (machine learning), and try to formulate it in a consistent way, reducing the gap between the two fields. Building on this formulation and problem definition, we propose a predictor structure based on the Kazantzis-Kravaris/Luenberger (KKL) observer and we show that KKL fits well into our general framework. Finally, we propose a constructive solution for this predictor that solely relies on a small set of trajectories measured from the system. Our experiments show that our solution allows to obtain an efficient predictor over a subset of the observation space.\n","date":1616457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616457600,"objectID":"7f8232c869d5c499df7e88a26462a2a7","permalink":"https://steevenjanny.github.io/post/deepkkl/","publishdate":"2021-03-23T00:00:00Z","relpermalink":"/post/deepkkl/","section":"post","summary":"Conference on Decision and Control (CDC 2021)","tags":["highlights","control"],"title":"Deep KKL: Data-driven Output Prediction for Non-Linear Systems","type":"post"},{"authors":["Steeven Janny","Fabien Baradel","Natalia Neverova","Madiha Nadri","Christian Wolf"],"categories":null,"content":"Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.\n","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"a4c86803c7eda1ced111f855b41494cc","permalink":"https://steevenjanny.github.io/post/filteredcophy/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/post/filteredcophy/","section":"post","summary":"ICLR 2022 (Oral)","tags":["highlights","physics"],"title":"Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space","type":"post"},{"authors":["Steeven Janny","Aurélien Bénéteau","Madiha Nadri","Julie Digne","Nicolas Thome","Christian Wolf"],"categories":null,"content":"Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE, a large-scale dataset of ∼1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure, comprised of 600 different scenes of three different types. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and global attention to learn long-range dependencies between spatially distant data points without needing a large number of iterations, as existing GNN methods do. We show that our transformer outperforms state-of-the-art performance on, both, existing synthetic and real datasets and on EAGLE. Finally, we highlight that our approach learns to attend to airflow, integrating complex information in a single iteration.\n","date":1674691200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674691200,"objectID":"c148e5dcfa797ceefb89cf5ede039494","permalink":"https://steevenjanny.github.io/post/eagledataset/","publishdate":"2023-01-26T00:00:00Z","relpermalink":"/post/eagledataset/","section":"post","summary":"ICLR 2023 (Poster)","tags":["highlights","physics"],"title":"EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers","type":"post"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://steevenjanny.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://steevenjanny.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://steevenjanny.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Steeven Janny","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://steevenjanny.github.io/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"}]