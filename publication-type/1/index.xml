<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Steeven Janny</title>
    <link>https://steevenjanny.github.io/publication-type/1/</link>
      <atom:link href="https://steevenjanny.github.io/publication-type/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 26 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://steevenjanny.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>1</title>
      <link>https://steevenjanny.github.io/publication-type/1/</link>
    </image>
    
    <item>
      <title>EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers</title>
      <link>https://steevenjanny.github.io/post/eagledataset/</link>
      <pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/eagledataset/</guid>
      <description>&lt;p&gt;Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the
Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a
notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural
networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We
attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE, a
large-scale dataset of âˆ¼1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving
flow source interacting with nonlinear scene structure, comprised of 600 different scenes of three different types. To
perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh
transformer. It leverages node clustering, graph pooling and global attention to learn long-range dependencies between
spatially distant data points without needing a large number of iterations, as existing GNN methods do. We show that our
transformer outperforms state-of-the-art performance on, both, existing synthetic and real datasets and on EAGLE.
Finally, we highlight that our approach learns to attend to airflow, integrating complex information in a single
iteration.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Reduced Nonlinear State-Space Models: an Output-Error Based Canonical Approach</title>
      <link>https://steevenjanny.github.io/post/reducedstatespace/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/reducedstatespace/</guid>
      <description>&lt;p&gt;The identification of a nonlinear dynamic model is an open topic in control theory, especially from sparse input-output measurements. A fundamental challenge of this problem is that very few to zero prior knowledge is available on both the state and the nonlinear system model. To cope with this challenge, we investigate the effectiveness of deep learning in the modeling of dynamic systems with nonlinear behavior by advocating an approach which relies on three main ingredients: (i) we show that under some structural conditions on the to-be-identified model, the state can be expressed in function of a sequence of the past inputs and outputs; (ii) this relation which we call the state map can be modelled by resorting to the well-documented approximation power of deep neural networks; (iii) taking then advantage of existing learning schemes, a state-space model can be finally identified. After the formulation and analysis of the approach, we show its ability to identify three different nonlinear systems. The performances are evaluated in terms of open-loop prediction on test data generated in simulation as well as a real world data-set of unmanned aerial vehicle flight measurements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space</title>
      <link>https://steevenjanny.github.io/post/filteredcophy/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/filteredcophy/</guid>
      <description>&lt;p&gt;Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep KKL: Data-driven Output Prediction for Non-Linear Systems</title>
      <link>https://steevenjanny.github.io/post/deepkkl/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/deepkkl/</guid>
      <description>&lt;p&gt;We address the problem of output prediction, ie. designing a model for autonomous nonlinear systems capable of forecasting their future observations. We first define a general framework bringing together the necessary properties for the development of such an output predictor. In particular, we look at this problem from two different viewpoints, control theory and data-driven techniques (machine learning), and try to formulate it in a consistent way, reducing the gap between the two fields. Building on this formulation and problem definition, we propose a predictor structure based on the Kazantzis-Kravaris/Luenberger (KKL) observer and we show that KKL fits well into our general framework. Finally, we propose a constructive solution for this predictor that solely relies on a small set of trajectories measured from the system. Our experiments show that our solution allows to obtain an efficient predictor over a subset of the observation space.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://steevenjanny.github.io/publication/example/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/publication/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
