<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>control | Steeven Janny</title>
    <link>https://steevenjanny.github.io/tag/control/</link>
      <atom:link href="https://steevenjanny.github.io/tag/control/index.xml" rel="self" type="application/rss+xml" />
    <description>control</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Mar 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://steevenjanny.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>control</title>
      <link>https://steevenjanny.github.io/tag/control/</link>
    </image>
    
    <item>
      <title>MoCap-less Quantitative Evaluation of Ego-Pose Estimation Without Ground Truth Measurements</title>
      <link>https://steevenjanny.github.io/post/mocapless/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/mocapless/</guid>
      <description>&lt;p&gt;The emergence of data-driven approaches for control and planning in robotics have highlighted the need for developing experimental robotic platforms for data collection. However, their implementation is often complex and expensive, in particular for flying and terrestrial robots where the precise estimation of the position requires motion capture devices (MoCap) or Lidar. In order to simplify the use of a robotic platform dedicated to research on a wide range of indoor and outdoor environments, we present a data validation tool for ego-pose estimation that does not require any equipment other than the on-board camera. The method and tool allow a rapid, visual and quantitative evaluation of the quality of ego-pose sensors and are sensitive to different sources of flaws in the acquisition chain, ranging from desynchronization of the sensor flows to misevaluation of the geometric parameters of the robotic platform. Using computer vision, the information from the sensors is used to calculate the motion of a semantic scene point through its projection to the 2D image space of the on-board camera. The deviations of these keypoints from references created with a semi-automatic tool allow rapid and simple quality assessment of the data collected on the platform. To demonstrate the performance of our method, we evaluate it on two challenging standard UAV datasets as well as one dataset taken from a terrestrial robot.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning of a Communication Policy for an Event-Triggered Observer for Linear Systems</title>
      <link>https://steevenjanny.github.io/post/eventtrigger/</link>
      <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/eventtrigger/</guid>
      <description>&lt;p&gt;The problem of learning a communication policy is investigated in this paper for the
design of an event-triggered observer for discrete-time LTI systems. Firstly, the event-triggered
observer problem is formulated as an optimisation problem. The existence of a solution to this
problem (communication policy) is investigated and it is verified if this solution still preserves
the stability of the estimation error dynamics. Secondly, an algorithm is provided to approximate
this optimal solution using neural networks and deep learning. Simulation examples are provided
to illustrate the effectiveness of the learned communication policies.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning to estimate UAV created turbulence from scene structure observed by onboard cameras</title>
      <link>https://steevenjanny.github.io/post/turbulences/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/turbulences/</guid>
      <description>&lt;p&gt;Controlling UAV flights precisely requires a realistic dynamic model and accurate state estimates from onboard sensors like UAV, GPS and visual observations. Obtaining a precise dynamic model is extremely difficult, as important aerodynamic effects are hard to model, in particular ground effect and other turbulences. While machine learning has been used in the past to estimate UAV created turbulence, this was restricted to flat grounds or diffuse in-flight air turbulences, both without taking into account obstacles. In this work we address the complex problem of estimating in-flight turbulences caused by obstacles, in particular the complex structures in cluttered environments. We learn a mapping from control input and images captured by onboard cameras to turbulence. In a large-scale setting, we train a model over a large number of different simulated photo-realistic environments loaded into the Habitat simulator augmented with a dynamic UAV model and an analytic ground effect model. We transfer the model from simulation to a real environment and evaluate on real UAV flights from the EuRoC-MAV dataset, showing that the model is capable of good sim2real generalization performance. The dataset will be made publicly available upon acceptance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning-based Output Tracking via Regulation and Contraction Theory </title>
      <link>https://steevenjanny.github.io/post/outputregulation/</link>
      <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/outputregulation/</guid>
      <description>&lt;p&gt;In this paper, we deal with output tracking control problems for input-affine nonlinear systems. We propose a deep
learning-based solution whose foundations lay in control theory. We design a two-step controller: a contraction-based
feedback stabilizer and feedforward action. The first component guarantees convergence to the steady-state trajectory on
which the tracking error is zero. The second one is inherited from output regulation theory and provides forward
invariantness of such a trajectory along the solutions of the system. To alleviate the need for heavy analytical
computations or online optimization, we rely on deep neural networks and link their approximation error to the tracking
one. Mimicking the analytical control structure, we split the learning task into two separate modules. For the
stabilizer module, we propose a switching objective function balancing feasibility of the solution and performance
improvement. We test our solution in a challenging environment to validate the proposed design.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Reduced Nonlinear State-Space Models: an Output-Error Based Canonical Approach</title>
      <link>https://steevenjanny.github.io/post/reducedstatespace/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/reducedstatespace/</guid>
      <description>&lt;p&gt;The identification of a nonlinear dynamic model is an open topic in control theory, especially from sparse input-output measurements. A fundamental challenge of this problem is that very few to zero prior knowledge is available on both the state and the nonlinear system model. To cope with this challenge, we investigate the effectiveness of deep learning in the modeling of dynamic systems with nonlinear behavior by advocating an approach which relies on three main ingredients: (i) we show that under some structural conditions on the to-be-identified model, the state can be expressed in function of a sequence of the past inputs and outputs; (ii) this relation which we call the state map can be modelled by resorting to the well-documented approximation power of deep neural networks; (iii) taking then advantage of existing learning schemes, a state-space model can be finally identified. After the formulation and analysis of the approach, we show its ability to identify three different nonlinear systems. The performances are evaluated in terms of open-loop prediction on test data generated in simulation as well as a real world data-set of unmanned aerial vehicle flight measurements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep KKL: Data-driven Output Prediction for Non-Linear Systems</title>
      <link>https://steevenjanny.github.io/post/deepkkl/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/deepkkl/</guid>
      <description>&lt;p&gt;We address the problem of output prediction, ie. designing a model for autonomous nonlinear systems capable of forecasting their future observations. We first define a general framework bringing together the necessary properties for the development of such an output predictor. In particular, we look at this problem from two different viewpoints, control theory and data-driven techniques (machine learning), and try to formulate it in a consistent way, reducing the gap between the two fields. Building on this formulation and problem definition, we propose a predictor structure based on the Kazantzis-Kravaris/Luenberger (KKL) observer and we show that KKL fits well into our general framework. Finally, we propose a constructive solution for this predictor that solely relies on a small set of trajectories measured from the system. Our experiments show that our solution allows to obtain an efficient predictor over a subset of the observation space.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
