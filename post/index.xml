<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Steeven Janny</title>
    <link>https://steevenjanny.github.io/post/</link>
      <atom:link href="https://steevenjanny.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://steevenjanny.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://steevenjanny.github.io/post/</link>
    </image>
    
    <item>
      <title>ITC, informatique tronc commun PSI, MP, PC</title>
      <link>https://steevenjanny.github.io/post/informatiqueellipses/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/informatiqueellipses/</guid>
      <description>&lt;p&gt;&lt;strong&gt;[English]&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This book aims to present, with clarity, all the knowledge necessary for the first and second years of preparatory classes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The basis of procedural programming in Python;&lt;/li&gt;
&lt;li&gt;Courses retracing the program of preparatory classes;&lt;/li&gt;
&lt;li&gt;Corrected exercises and training for the written and oral tests of the competitions;&lt;/li&gt;
&lt;li&gt;Additional resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;[French]&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cet ouvrage a pour but de présenter, avec clarté, toutes les connaissances nécessaires aux premières et deuxièmes années de classes préparatoires :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;La base de la programmation procédurale en Python ;&lt;/li&gt;
&lt;li&gt;Des cours retraçant le programme des classes préparatoires ;&lt;/li&gt;
&lt;li&gt;Des exercices corrigés et des entrainements aux épreuves écrites et orales des concours ;&lt;/li&gt;
&lt;li&gt;Des ressources complémentaires.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Learning Reduced Nonlinear State-Space Models: an Output-Error Based Canonical Approach</title>
      <link>https://steevenjanny.github.io/post/reducedstatespace/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/reducedstatespace/</guid>
      <description>&lt;p&gt;The identification of a nonlinear dynamic model is an open topic in control theory, especially from sparse input-output measurements. A fundamental challenge of this problem is that very few to zero prior knowledge is available on both the state and the nonlinear system model. To cope with this challenge, we investigate the effectiveness of deep learning in the modeling of dynamic systems with nonlinear behavior by advocating an approach which relies on three main ingredients: (i) we show that under some structural conditions on the to-be-identified model, the state can be expressed in function of a sequence of the past inputs and outputs; (ii) this relation which we call the state map can be modelled by resorting to the well-documented approximation power of deep neural networks; (iii) taking then advantage of existing learning schemes, a state-space model can be finally identified. After the formulation and analysis of the approach, we show its ability to identify three different nonlinear systems. The performances are evaluated in terms of open-loop prediction on test data generated in simulation as well as a real world data-set of unmanned aerial vehicle flight measurements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning to estimate UAV created turbulence from scene structure observed by onboard cameras</title>
      <link>https://steevenjanny.github.io/post/turbulences/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/turbulences/</guid>
      <description>&lt;p&gt;Controlling UAV flights precisely requires a realistic dynamic model and accurate state estimates from onboard sensors like UAV, GPS and visual observations. Obtaining a precise dynamic model is extremely difficult, as important aerodynamic effects are hard to model, in particular ground effect and other turbulences. While machine learning has been used in the past to estimate UAV created turbulence, this was restricted to flat grounds or diffuse in-flight air turbulences, both without taking into account obstacles. In this work we address the complex problem of estimating in-flight turbulences caused by obstacles, in particular the complex structures in cluttered environments. We learn a mapping from control input and images captured by onboard cameras to turbulence. In a large-scale setting, we train a model over a large number of different simulated photo-realistic environments loaded into the Habitat simulator augmented with a dynamic UAV model and an analytic ground effect model. We transfer the model from simulation to a real environment and evaluate on real UAV flights from the EuRoC-MAV dataset, showing that the model is capable of good sim2real generalization performance. The dataset will be made publicly available upon acceptance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space</title>
      <link>https://steevenjanny.github.io/post/filteredcophy/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/filteredcophy/</guid>
      <description>&lt;p&gt;Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MoCap-less Quantitative Evaluation of Ego-Pose Estimation Without Ground Truth Measurements</title>
      <link>https://steevenjanny.github.io/post/mocapless/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/mocapless/</guid>
      <description>&lt;p&gt;The emergence of data-driven approaches for control and planning in robotics have highlighted the need for developing experimental robotic platforms for data collection. However, their implementation is often complex and expensive, in particular for flying and terrestrial robots where the precise estimation of the position requires motion capture devices (MoCap) or Lidar. In order to simplify the use of a robotic platform dedicated to research on a wide range of indoor and outdoor environments, we present a data validation tool for ego-pose estimation that does not require any equipment other than the on-board camera. The method and tool allow a rapid, visual and quantitative evaluation of the quality of ego-pose sensors and are sensitive to different sources of flaws in the acquisition chain, ranging from desynchronization of the sensor flows to misevaluation of the geometric parameters of the robotic platform. Using computer vision, the information from the sensors is used to calculate the motion of a semantic scene point through its projection to the 2D image space of the on-board camera. The deviations of these keypoints from references created with a semi-automatic tool allow rapid and simple quality assessment of the data collected on the platform. To demonstrate the performance of our method, we evaluate it on two challenging standard UAV datasets as well as one dataset taken from a terrestrial robot.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep KKL: Data-driven Output Prediction for Non-Linear Systems</title>
      <link>https://steevenjanny.github.io/post/deepkkl/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/deepkkl/</guid>
      <description>&lt;p&gt;We address the problem of output prediction, ie. designing a model for autonomous nonlinear systems capable of forecasting their future observations. We first define a general framework bringing together the necessary properties for the development of such an output predictor. In particular, we look at this problem from two different viewpoints, control theory and data-driven techniques (machine learning), and try to formulate it in a consistent way, reducing the gap between the two fields. Building on this formulation and problem definition, we propose a predictor structure based on the Kazantzis-Kravaris/Luenberger (KKL) observer and we show that KKL fits well into our general framework. Finally, we propose a constructive solution for this predictor that solely relies on a small set of trajectories measured from the system. Our experiments show that our solution allows to obtain an efficient predictor over a subset of the observation space.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Physique-chimie PSI-PSI* Concours X, ENS, CentraleSupélec, Mines-Ponts, CCINP</title>
      <link>https://steevenjanny.github.io/post/physiqueellipses/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/physiqueellipses/</guid>
      <description>&lt;p&gt;&lt;strong&gt;[English]&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This book includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A selection of the most representative exercises from the oral examinations for the X, ENS, Centrale-Supélec, Mines-Ponts and CCINP competitions.&lt;/li&gt;
&lt;li&gt;Answers enriched with comments including: method points, course reminders, remarks on questions, writing advice, remarks from jury reports, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;[French]&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cet ouvrage regroupe :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Une sélection d’exercices les plus représentatifs des oraux des concours X, ENS, Centrale-Supélec, Mines-Ponts et CCINP.&lt;/li&gt;
&lt;li&gt;Des corrigés enrichis de commentaires comportant : des points méthodes, des rappels de cours, des remarques sur les questions, des conseils de rédaction, des remarques issues des rapports de jurys, etc.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Attended temperature scaling: a practical approach for calibrating deep neural networks</title>
      <link>https://steevenjanny.github.io/post/attendedtemperature/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://steevenjanny.github.io/post/attendedtemperature/</guid>
      <description>&lt;p&gt;Recently, Deep Neural Networks (DNNs) have been achieving impressive results on wide range of tasks. However, they suffer from being well-calibrated. In decision-making applications, such as autonomous driving or medical diagnosing, the confidence of deep networks plays an important role to bring the trust and reliability to the system. To calibrate the deep networks&amp;rsquo; confidence, many probabilistic and measure-based approaches are proposed. Temperature Scaling (TS) is a state-of-the-art among measure-based calibration methods which has low time and memory complexity as well as effectiveness. In this paper, we study TS and show it does not work properly when the validation set that TS uses for calibration has small size or contains noisy-labeled samples. TS also cannot calibrate highly accurate networks as well as non-highly accurate ones. Accordingly, we propose Attended Temperature Scaling (ATS) which preserves the advantages of TS while improves calibration in aforementioned challenging situations. We provide theoretical justifications for ATS and assess its effectiveness on wide range of deep models and datasets. We also compare the calibration results of TS and ATS on skin lesion detection application as a practical problem where well-calibrated system can play important role in making a decision.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
